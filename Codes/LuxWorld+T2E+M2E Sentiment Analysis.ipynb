{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a14a23b0",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis: LuxWorld and Travel to Earn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519088b2",
   "metadata": {},
   "source": [
    "Currently, sentiment analysis is one of the most popular research techniques to understand the opinions and feelings of the people based on the text data. Machine learning is also one of the popular tools for analyzing the data based on the large amount of data. Nowadays, many researchers try to use the good points of the machine learning to perform the sentiment and opinion mining. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b5dfb9",
   "metadata": {},
   "source": [
    "The present study analyzes the sentiments of Voice of the Customer from LuxWorld and Travel-to-earn users using machine learning algorithms, which learn more quickly and with less complexity than deep learning algorithms. Voice of the Customer is concern about what individual customer is saying about products or services. It means analyzing the reviews and feedback of the customers. VOC is a key element of Customer Experience Management. VOC helps in identifying new opportunities for product inventions.\n",
    "\n",
    "In this notebook, machine learning algorithms are optimized with English-language tweets expressing sentiments about events, feelings and experiences from October to December 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89075b52",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Data Scraping and Collection\n",
    "2. Data Preprocessing\n",
    "3. Sentiment Analysis\n",
    "4. EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe2793e",
   "metadata": {},
   "source": [
    "## 1. Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478724bb",
   "metadata": {},
   "source": [
    "Twitter is one of the most important data sources for data scientists. Data scientists can extract data from Twitter with web scraping tools. There are several libraries to do this, such as Tweepy and Snscrape. Tweepy is an easy-to-use Python library but it is limited with extracted tweets. Therefore, we will use Snscrape, which can scrape data from other services like Facebook, Instagram, Reddit, and Telegram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce54f2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snscrape in c:\\users\\vimoney\\anaconda3\\lib\\site-packages (0.4.3.20220106)\n",
      "Requirement already satisfied: lxml in c:\\users\\vimoney\\anaconda3\\lib\\site-packages (from snscrape) (4.6.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\vimoney\\anaconda3\\lib\\site-packages (from snscrape) (4.10.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\vimoney\\anaconda3\\lib\\site-packages (from snscrape) (2.26.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\vimoney\\anaconda3\\lib\\site-packages (from snscrape) (3.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vimoney\\anaconda3\\lib\\site-packages (from beautifulsoup4->snscrape) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vimoney\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vimoney\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vimoney\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vimoney\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\vimoney\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install snscrape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a66b44c",
   "metadata": {},
   "source": [
    "So, I’m just going to scrape two days of tweets and set the tweet limit to 3000 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da83dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b51fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets(n_tweets, search_term, language, start_date, end_date):\n",
    "\n",
    "    # Creating list to append tweet data to\n",
    "    tweets_list2 = []\n",
    "\n",
    "    # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{search_term} lang:{language} since:{start_date} until:{end_date}').get_items()):\n",
    "        if i>n_tweets:\n",
    "            break\n",
    "        tweets_list2.append([tweet.date, tweet.user.username, tweet.id, tweet.content])\n",
    "\n",
    "    # Creating a dataframe from the tweets list above\n",
    "    tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime', 'User', 'Tweet Id', 'Text'])\n",
    "    return tweets_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d342927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df=tweets(100000, 'Luxworld','en', '2022-10-01', '2022-12-26') \n",
    "#comment it out once you have gathered your data to avoid running out of the wait time gather the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "401e68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe to csv\n",
    "tweets_df.to_csv(\"tweets_luxworld.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8e5ccff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-25 15:08:39+00:00</td>\n",
       "      <td>0xiqbalSCP001</td>\n",
       "      <td>1607030569472528386</td>\n",
       "      <td>I just won a raffle for @buster_ranger from @L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-25 12:47:32+00:00</td>\n",
       "      <td>PealsSamyeli</td>\n",
       "      <td>1606995057843789828</td>\n",
       "      <td>@AycanEverley @frjsr714810 @Gameverse_ @ethere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-25 11:02:16+00:00</td>\n",
       "      <td>TommyWang2211</td>\n",
       "      <td>1606968564254404610</td>\n",
       "      <td>@LuxWorld_ When #LuxWorld combines #Move2Earn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-25 10:55:43+00:00</td>\n",
       "      <td>james19_oliver</td>\n",
       "      <td>1606966915850989570</td>\n",
       "      <td>@LucasMaxxx11 @LuxWorld_ maybe both in real li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-25 10:54:06+00:00</td>\n",
       "      <td>james19_oliver</td>\n",
       "      <td>1606966510962216960</td>\n",
       "      <td>@LuxWorld_ LFG #LuxWorld, I believe in your pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime            User             Tweet Id  \\\n",
       "0 2022-12-25 15:08:39+00:00   0xiqbalSCP001  1607030569472528386   \n",
       "1 2022-12-25 12:47:32+00:00    PealsSamyeli  1606995057843789828   \n",
       "2 2022-12-25 11:02:16+00:00   TommyWang2211  1606968564254404610   \n",
       "3 2022-12-25 10:55:43+00:00  james19_oliver  1606966915850989570   \n",
       "4 2022-12-25 10:54:06+00:00  james19_oliver  1606966510962216960   \n",
       "\n",
       "                                                Text  \n",
       "0  I just won a raffle for @buster_ranger from @L...  \n",
       "1  @AycanEverley @frjsr714810 @Gameverse_ @ethere...  \n",
       "2  @LuxWorld_ When #LuxWorld combines #Move2Earn ...  \n",
       "3  @LucasMaxxx11 @LuxWorld_ maybe both in real li...  \n",
       "4  @LuxWorld_ LFG #LuxWorld, I believe in your pr...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98fe73ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6838, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64402023",
   "metadata": {},
   "source": [
    "We only collect 6838 tweets of Luxworld, lower than I expected (:D). But it is ok with a new project like LuxWorld. Now we move to collect data for travel to earn trend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f345a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df1=tweets(10000, 'Travel2Earn','en', '2022-10-01', '2022-12-26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a30077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe to csv\n",
    "tweets_df1.to_csv(\"tweets_t2e.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c297cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape \n",
    "tweets_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e95a8dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-25 11:02:16+00:00</td>\n",
       "      <td>TommyWang2211</td>\n",
       "      <td>1606968564254404610</td>\n",
       "      <td>@LuxWorld_ When #LuxWorld combines #Move2Earn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-23 19:30:56+00:00</td>\n",
       "      <td>NobleMoody_357</td>\n",
       "      <td>1606371799872438272</td>\n",
       "      <td>#GetFit #Move2Earn #Play2Earn #Travel2Earn rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-21 18:18:57+00:00</td>\n",
       "      <td>KnShayeMedia</td>\n",
       "      <td>1605628909902368769</td>\n",
       "      <td>Let’s Get It! #GetFit #Tagcoin #Tagprotocol #G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-20 16:02:15+00:00</td>\n",
       "      <td>sandy_carter</td>\n",
       "      <td>1605232117494988802</td>\n",
       "      <td>And another amazing @unstoppablewebpartner - @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-20 02:00:01+00:00</td>\n",
       "      <td>GetFitMining</td>\n",
       "      <td>1605020162385534976</td>\n",
       "      <td>1⃣ Follow us\\n2⃣ Retweet\\n3⃣ Tag 3 friends &amp;am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime            User             Tweet Id  \\\n",
       "0 2022-12-25 11:02:16+00:00   TommyWang2211  1606968564254404610   \n",
       "1 2022-12-23 19:30:56+00:00  NobleMoody_357  1606371799872438272   \n",
       "2 2022-12-21 18:18:57+00:00    KnShayeMedia  1605628909902368769   \n",
       "3 2022-12-20 16:02:15+00:00    sandy_carter  1605232117494988802   \n",
       "4 2022-12-20 02:00:01+00:00    GetFitMining  1605020162385534976   \n",
       "\n",
       "                                                Text  \n",
       "0  @LuxWorld_ When #LuxWorld combines #Move2Earn ...  \n",
       "1  #GetFit #Move2Earn #Play2Earn #Travel2Earn rew...  \n",
       "2  Let’s Get It! #GetFit #Tagcoin #Tagprotocol #G...  \n",
       "3  And another amazing @unstoppablewebpartner - @...  \n",
       "4  1⃣ Follow us\\n2⃣ Retweet\\n3⃣ Tag 3 friends &am...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2075015",
   "metadata": {},
   "source": [
    "The amount of tweet for Travel2Earn is quite little so I decide to scrape more data from the trend Move2Earn because Travel2Earn was born by Move2Earn trend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d46b6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df2=tweets(10000, 'Move2Earn','en', '2022-10-01', '2022-12-26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9757c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe to csv\n",
    "tweets_df2.to_csv(\"tweets_m2e.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ae369db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-25 23:51:50+00:00</td>\n",
       "      <td>s13yukio</td>\n",
       "      <td>1607162231590129665</td>\n",
       "      <td>I'm joining TipTop's 1st ever community giveaw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-25 23:18:16+00:00</td>\n",
       "      <td>haydn239</td>\n",
       "      <td>1607153784676810753</td>\n",
       "      <td>@ktrainUSA_STEPN Jim and bit boy critiquing SO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-25 23:13:38+00:00</td>\n",
       "      <td>CoinHuntWorld</td>\n",
       "      <td>1607152619583062016</td>\n",
       "      <td>Congratulations @spacecubie, for being the fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-25 23:11:48+00:00</td>\n",
       "      <td>karadasakin</td>\n",
       "      <td>1607152156204847106</td>\n",
       "      <td>I'm joining TipTop's 1st ever community giveaw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-25 22:21:19+00:00</td>\n",
       "      <td>lehomonyet</td>\n",
       "      <td>1607139451964395520</td>\n",
       "      <td>Hey @1 @2 - Check out FightOut - the best Move...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime           User             Tweet Id  \\\n",
       "0 2022-12-25 23:51:50+00:00       s13yukio  1607162231590129665   \n",
       "1 2022-12-25 23:18:16+00:00       haydn239  1607153784676810753   \n",
       "2 2022-12-25 23:13:38+00:00  CoinHuntWorld  1607152619583062016   \n",
       "3 2022-12-25 23:11:48+00:00    karadasakin  1607152156204847106   \n",
       "4 2022-12-25 22:21:19+00:00     lehomonyet  1607139451964395520   \n",
       "\n",
       "                                                Text  \n",
       "0  I'm joining TipTop's 1st ever community giveaw...  \n",
       "1  @ktrainUSA_STEPN Jim and bit boy critiquing SO...  \n",
       "2  Congratulations @spacecubie, for being the fir...  \n",
       "3  I'm joining TipTop's 1st ever community giveaw...  \n",
       "4  Hey @1 @2 - Check out FightOut - the best Move...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47849a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7810, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d54a71f",
   "metadata": {},
   "source": [
    "So, we're done with scraping data for this notebook. Let's move to perform a Twitter sentiment analysis. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
